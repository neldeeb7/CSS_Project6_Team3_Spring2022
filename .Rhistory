#Assignment using <- or =
x <- 1
x
y = 2
y
#Check equality using ==
x == y
x != y
pets_vector <- c('dog', 'cat', 'parrot')
pets_list <- list('dog', 'cat', 'parrot')
num_vector <- c(1, 2, 3)
mixed_data <- c(1, 'dog', 2, 'cat')
dog <- 'dog'
class(pets_vector)
class(pets_list)
class(num_vector)
class(mixed_data)
class(dog)
for (pet in pets_vector) {
print(pet)
}
numbers <- 1:1000000
print(system.time(numbers_log_vec <- log(numbers)))
numbers_for_loop <- list()
print(system.time(for (number in numbers) {
numbers_for_loop[number] <- log(number)
}))
minus_one <- function(num) {
nums_minus_one <- num - 1
return(nums_minus_one)
}
minus_one_list <- list()
system.time(for (num in numbers) {
minus_one_list[num] <- minus_one(num)
})
system.time(apply_minus_one <- sapply(numbers, minus_one))
apply_minus_one[1]
minus_one <- function(num) {
nums_minus_one <- num - 1
return(nums_minus_one)
}
minus_one_list <- list()
system.time(for (num in numbers) {
minus_one_list[num] <- minus_one(num)
})
system.time(apply_minus_one <- sapply(numbers, minus_one))
apply_minus_one[1]
install.packages('here')
here::i_am('R Refresher Student.Rmd')
install.packages('here')
here::i_am('R-Refresher Student.Rmd')
library(here)
setwd(here())
install.packages('here')
here::i_am('R-Refresher Student.Rmd')
library(here)
setwd(here())
install.packages("here")
library(here)
install.packages('here')
here::i_am('R-Refresher Student.Rmd')
library(here)
setwd(here())
install.packages("here")
library(here)
setwd(here())
install.packages('here')
here::i_am('R-Refresher Student.Rmd')
library(here)
setwd(here())
install.packages("here")
setwd(here())
getwd()
install.packages('here')
#Tidyverse Import
library(readr)
df <- read_csv("../../data/strength.csv")
head(df)
names(df)
dim(df)
library(here)
getwd()
#Add a column that creates a new variable y_2 as y times 2 using tidyverse tools
#install.packages("dplyr")
#library(tidyverse)
library(dplyr)
df = mutate(df, y_2 = y*2)
head(df)
#Note this is equivalent to the base R command: df$y_2 = (df$y)*2
#Select or drop columns using the select() function
df = select(df, -y_2)
head(df)
#piping
tidy_df <- df %>%
rename(treatment = tx) %>%
mutate(rescale_y = y * 1000)
head(tidy_df)
# Remove post-treatment covariates & outcome variable
ypsps_dropna_droplater = ypsps %>%
select(!contains("1973") & !contains("1982")) %>%
na.omit()
# Load tidyverse and MatchIt
# Feel free to load other libraries as you wish
library(tidyverse)
library(MatchIt)
library(ggplot2)
set.seed(10)
# Load ypsps data
ypsps <- read_csv('data/ypsps.csv')
head(ypsps)
# Generate a vector that randomly assigns each unit to treatment/control
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5)) ## 0 = Control; 1 = Treatment
# Choose a baseline covariate (use dplyr for this)
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
# Visualize the distribution by treatment/control (ggplot)
ggplot(sample_df, aes(x = student_demonstrate, fill = factor(rdm_vtr))) +
geom_bar() +
facet_grid(rdm_vtr~.) +
labs(title = "Distribution of Student Participation in Demonstrations", fill = "Random \nAssignment\n")
# Simulate this 10,000 times
distr_vec <- vector()
for (iter_num in 1:10000) {
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5))
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
distr_vec <- c(distr_vec,
(sum(sample_df[which(sample_df$rdm_vtr==1), 1]) / nrow(sample_df))
)
}
ggplot() +
geom_histogram(aes(distr_vec))
# Select covariates that represent the "true" model for selection into college
sel_college_vars <- c("student_GPA", "student_SchOfficer", "student_SchClub", "student_SchOfficer", "student_SchPublish", "student_Hobby", "student_SchClub", "student_OccClub", "student_NeighClub", "student_RelClub", "student_YouthOrg", "student_MiscClub", "student_ClubLev", "student_Knowledge", "student_FPlans", "student_Newspaper", "student_Magazine", "student_Gen", "student_Race", "parent_EducHH", "parent_EducW", "parent_HHInc", "parent_Knowledge")
##Logic for choosing the above covariates:
# student's GPA and school involvement are part of admissions
# student knowledge & whether they finish plans
# students' desire to read probably influences future plans for education
# parental educ, knowledge, and income matter
# gender and race of student influences college attendance
# Fit model with matching
glm_formula <- paste("college ~ ",paste(sel_college_vars, collapse=" + "))
matching_ps_att <- matchit(formula = formula(glm_formula),
data = ypsps,
method = "nearest",
distance = "glm",
link = "logit",
estimand = "ATT",
replace = TRUE,
#because there is imbalance in the number of college attendees and non-attendees
ratio = 2)
# Save data from model for later
matching_ps_att_data <- match.data(matching_ps_att)
# Report the overall balance and the proportion of covariates that meet the balance threshold
# Install cobalt
install.packages("cobalt")
library(cobalt)
# Use cobalt to create a balance table
balance_table <- bal.tab(x = matching_ps_att, thresholds = .1)
balance_table
# Only 12 out of 22 covariates are balanced post-matching
# We have 306 controls matched to 803 treated. 145 controls had no match.
summary(matching_ps_att) # this shows percent balance improvement post-matching
# Balance got worse for these covariates after matching:
## student_SchClub                    (-16.6%)
## student_Hobby                      (-588.3%)
## student_Race                       (-8.2%)
# However, student_Race is still balanced in the end, meeting the threshold
# Examine and plot the balance for the top 10 covariates
# First, create a data frame with covariates, their coefficients' absolute values, and keep only the ones with the largest coefs
top_coef_df <- data.frame(abs(matching_ps_att$model$coefficients)) %>%
slice_max(abs.matching_ps_att.model.coefficients., n = 11) #11, not 10, to include the intercept AND 10 covariates
# Save the names of the top 10 covariates.
top_coefs <- c(rownames(top_coef_df))
top_coefs <- top_coefs[-c(1)] #removing the intercept
# Generate balance stats for top 10 covariates
bal_df <- balance_table$Balance[top_coefs,]
bal_df
# Only 5 out of 10 of the top covariates are balanced post-matching
# Plot it
# There is no way to plot only a subset of variables, so instead of plotting top_coefs, we plot them all.
summary(matching_ps_att) %>% plot()
# Remove post-treatment covariates & outcome variable
ypsps_dropna_droplater = ypsps %>%
select(!contains("1973") & !contains("1982")) %>%
na.omit()
pre_treat_df = ypsps_dropna_droplater %>%
select(!contains("student_ppnscal")) %>%
select(!"college") # we don't want "college" to be picked as a covariate for college attendance
pre_covars_quant = ncol(pre_treat_df)
pre_covars = colnames(pre_treat_df)
# Plot ATT v. proportion
simulations_df %>%
ggplot() +
geom_smooth(aes(x = prop_threshold, y = ATT)) +
ggtitle("Average Treatment Effect on Treated by Proportion of Covariates Meeting Balance Threshold") +
xlab("Proportion of Covariates Meeting Threshold") +
ylab("ATT")
# Generate empty data frame to hold stats from random simulations
simulations_df = data.frame(matrix(ncol=3, nrow=1000))
colnames(simulations_df) = c("mean_improvement", "prop_threshold", "ATT")
# Generate empty nested list to hold models
simul_models = list()
# Simulate random selection of features 10k+ times
r <- nrow(simulations_df)
for (sim in 1:r) {
# randomly select a quantity of pre-treatment covariates
num_vars = sample(1:pre_covars_quant, 1)
# randomly select covariates, save as "features", save in df, and in formula syntax form
features = sample(x = pre_covars, size = num_vars)
features_form = paste("college ~ ",paste(features,collapse=" + "))
# run propensity score matching model, using nearest neighbor method, linear model, ATT estimand
random_ps_att <- matchit(formula = formula(features_form),
data = ypsps_dropna_droplater, # fullest data while omitting NAs and irrelevant columns
method = "nearest",
distance = "glm",
link = "logit",
estimand = "ATT",
replace = TRUE,
ratio = 2)
# save model in df
simul_models[[sim]] <- random_ps_att
# generate summary information for the matching model, extract percent improvement, and save in df
random_ps_att_sum = summary(random_ps_att)
random_ps_att_sum_impr = random_ps_att_sum[["reduction"]]
mean_improved = mean(random_ps_att_sum_impr[,1])
simulations_df$mean_improvement[sim] <- mean_improved
# create cobalt object to fetch the proportion of covariates meeting the balance threshold, and save this proportion to the df
co_bal <- bal.tab(x = random_ps_att, thresholds = .1)
prop_bal = co_bal[["Balanced.mean.diffs"]][["count"]][1] / (co_bal[["Balanced.mean.diffs"]][["count"]][1] + co_bal[["Balanced.mean.diffs"]][["count"]][2])
simulations_df$prop_threshold[sim] = prop_bal
# save the data from the matching model and use for linear, matched regression on the political participation outcome. From this, get the ATT and save it in the df.
random_ps_att_data = match.data(random_ps_att)
features_form2 = paste("student_ppnscal ~ college + ",paste(features,collapse=" + "))
lm_ps_att = lm(formula = features_form2,
data = random_ps_att_data,
weights = weights)
lm_ps_att_sum = summary(lm_ps_att)
ATT_ps = lm_ps_att_sum$coefficients["college", "Estimate"]
simulations_df$ATT[sim] <- ATT_ps
}
# Load tidyverse and MatchIt
# Feel free to load other libraries as you wish
library(tidyverse)
library(MatchIt)
library(ggplot2)
library(dplyr)
set.seed(10)
# Load ypsps data
ypsps <- read_csv('data/ypsps.csv')
head(ypsps)
# Generate a vector that randomly assigns each unit to treatment/control
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5)) ## 0 = Control; 1 = Treatment
# Choose a baseline covariate (use dplyr for this)
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
# Visualize the distribution by treatment/control (ggplot)
ggplot(sample_df, aes(x = student_demonstrate, fill = factor(rdm_vtr))) +
geom_bar() +
facet_grid(rdm_vtr~.) +
labs(title = "Distribution of Student Participation in Demonstrations", fill = "Random \nAssignment\n")
# Simulate this 10,000 times
distr_vec <- vector()
for (iter_num in 1:10000) {
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5))
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
distr_vec <- c(distr_vec,
(sum(sample_df[which(sample_df$rdm_vtr==1), 1]) / nrow(sample_df))
)
}
ggplot() +
geom_histogram(aes(distr_vec))
# Select covariates that represent the "true" model for selection into college
sel_college_vars <- c("student_GPA", "student_SchOfficer", "student_SchClub", "student_SchOfficer", "student_SchPublish", "student_Hobby", "student_SchClub", "student_OccClub", "student_NeighClub", "student_RelClub", "student_YouthOrg", "student_MiscClub", "student_ClubLev", "student_Knowledge", "student_FPlans", "student_Newspaper", "student_Magazine", "student_Gen", "student_Race", "parent_EducHH", "parent_EducW", "parent_HHInc", "parent_Knowledge")
##Logic for choosing the above covariates:
# student's GPA and school involvement are part of admissions
# student knowledge & whether they finish plans
# students' desire to read probably influences future plans for education
# parental educ, knowledge, and income matter
# gender and race of student influences college attendance
# Fit model with matching
glm_formula <- paste("college ~ ",paste(sel_college_vars, collapse=" + "))
matching_ps_att <- matchit(formula = formula(glm_formula),
data = ypsps,
method = "nearest",
distance = "glm",
link = "logit",
estimand = "ATT",
replace = TRUE,
#because there is imbalance in the number of college attendees and non-attendees
ratio = 2)
# Save data from model for later
matching_ps_att_data <- match.data(matching_ps_att)
# Report the overall balance and the proportion of covariates that meet the balance threshold
# Install cobalt
install.packages("cobalt")
library(cobalt)
# Use cobalt to create a balance table
balance_table <- bal.tab(x = matching_ps_att, thresholds = .1)
balance_table
# Only 12 out of 22 covariates are balanced post-matching
# We have 306 controls matched to 803 treated. 145 controls had no match.
summary(matching_ps_att) # this shows percent balance improvement post-matching
# Balance got worse for these covariates after matching:
## student_SchClub                    (-16.6%)
## student_Hobby                      (-588.3%)
## student_Race                       (-8.2%)
# However, student_Race is still balanced in the end, meeting the threshold
# Examine and plot the balance for the top 10 covariates
# First, create a data frame with covariates, their coefficients' absolute values, and keep only the ones with the largest coefs
top_coef_df <- data.frame(abs(matching_ps_att$model$coefficients)) %>%
slice_max(abs.matching_ps_att.model.coefficients., n = 11) #11, not 10, to include the intercept AND 10 covariates
# Save the names of the top 10 covariates.
top_coefs <- c(rownames(top_coef_df))
top_coefs <- top_coefs[-c(1)] #removing the intercept
# Generate balance stats for top 10 covariates
bal_df <- balance_table$Balance[top_coefs,]
bal_df
# Only 5 out of 10 of the top covariates are balanced post-matching
# Plot it
# There is no way to plot only a subset of variables, so instead of plotting top_coefs, we plot them all.
summary(matching_ps_att) %>% plot()
# Remove post-treatment covariates & outcome variable
ypsps_dropna_droplater = ypsps %>%
select(!contains("1973") & !contains("1982")) %>%
na.omit()
pre_treat_df = ypsps_dropna_droplater %>%
select(!contains("student_ppnscal")) %>%
select(!"college") # we don't want "college" to be picked as a covariate for college attendance
pre_covars_quant = ncol(pre_treat_df)
pre_covars = colnames(pre_treat_df)
# Plot ATT v. proportion
simulations_df %>%
ggplot() +
geom_smooth(aes(x = prop_threshold, y = ATT)) +
ggtitle("Average Treatment Effect on Treated by Proportion of Covariates Meeting Balance Threshold") +
xlab("Proportion of Covariates Meeting Threshold") +
ylab("ATT")
# Load tidyverse and MatchIt
# Feel free to load other libraries as you wish
library(tidyverse)
library(MatchIt)
library(ggplot2)
library(dplyr)
set.seed(10)
# Load ypsps data
ypsps <- read_csv('data/ypsps.csv')
head(ypsps)
# Generate a vector that randomly assigns each unit to treatment/control
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5)) ## 0 = Control; 1 = Treatment
# Choose a baseline covariate (use dplyr for this)
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
# Visualize the distribution by treatment/control (ggplot)
ggplot(sample_df, aes(x = student_demonstrate, fill = factor(rdm_vtr))) +
geom_bar() +
facet_grid(rdm_vtr~.) +
labs(title = "Distribution of Student Participation in Demonstrations", fill = "Random \nAssignment\n")
# Simulate this 10,000 times
distr_vec <- vector()
for (iter_num in 1:10000) {
rdm_vtr <- sample(0:1, size = nrow(ypsps), replace = TRUE, prob = c(0.5,0.5))
sample_df = ypsps %>%
select(student_demonstrate) %>%
mutate(rdm_vtr)
distr_vec <- c(distr_vec,
(sum(sample_df[which(sample_df$rdm_vtr==1), 1]) / nrow(sample_df))
)
}
ggplot() +
geom_histogram(aes(distr_vec))
# Select covariates that represent the "true" model for selection into college
sel_college_vars <- c("student_GPA", "student_SchOfficer", "student_SchClub", "student_SchOfficer", "student_SchPublish", "student_Hobby", "student_SchClub", "student_OccClub", "student_NeighClub", "student_RelClub", "student_YouthOrg", "student_MiscClub", "student_ClubLev", "student_Knowledge", "student_FPlans", "student_Newspaper", "student_Magazine", "student_Gen", "student_Race", "parent_EducHH", "parent_EducW", "parent_HHInc", "parent_Knowledge")
##Logic for choosing the above covariates:
# student's GPA and school involvement are part of admissions
# student knowledge & whether they finish plans
# students' desire to read probably influences future plans for education
# parental educ, knowledge, and income matter
# gender and race of student influences college attendance
# Fit model with matching
glm_formula <- paste("college ~ ",paste(sel_college_vars, collapse=" + "))
matching_ps_att <- matchit(formula = formula(glm_formula),
data = ypsps,
method = "nearest",
distance = "glm",
link = "logit",
estimand = "ATT",
replace = TRUE,
#because there is imbalance in the number of college attendees and non-attendees
ratio = 2)
# Save data from model for later
matching_ps_att_data <- match.data(matching_ps_att)
# Report the overall balance and the proportion of covariates that meet the balance threshold
# Install cobalt
install.packages("cobalt")
library(cobalt)
# Use cobalt to create a balance table
balance_table <- bal.tab(x = matching_ps_att, thresholds = .1)
balance_table
# Only 12 out of 22 covariates are balanced post-matching
# We have 306 controls matched to 803 treated. 145 controls had no match.
summary(matching_ps_att) # this shows percent balance improvement post-matching
# Balance got worse for these covariates after matching:
## student_SchClub                    (-16.6%)
## student_Hobby                      (-588.3%)
## student_Race                       (-8.2%)
# However, student_Race is still balanced in the end, meeting the threshold
# Examine and plot the balance for the top 10 covariates
# First, create a data frame with covariates, their coefficients' absolute values, and keep only the ones with the largest coefs
top_coef_df <- data.frame(abs(matching_ps_att$model$coefficients)) %>%
slice_max(abs.matching_ps_att.model.coefficients., n = 11) #11, not 10, to include the intercept AND 10 covariates
# Save the names of the top 10 covariates.
top_coefs <- c(rownames(top_coef_df))
top_coefs <- top_coefs[-c(1)] #removing the intercept
# Generate balance stats for top 10 covariates
bal_df <- balance_table$Balance[top_coefs,]
bal_df
# Only 5 out of 10 of the top covariates are balanced post-matching
# Plot it
# There is no way to plot only a subset of variables, so instead of plotting top_coefs, we plot them all.
summary(matching_ps_att) %>% plot()
# Remove post-treatment covariates & outcome variable
ypsps_dropna_droplater = ypsps %>%
select(!contains("1973") & !contains("1982")) %>%
na.omit()
pre_treat_df = ypsps_dropna_droplater %>%
select(!contains("student_ppnscal")) %>%
select(!"college") # we don't want "college" to be picked as a covariate for college attendance
pre_covars_quant = ncol(pre_treat_df)
pre_covars = colnames(pre_treat_df)
# Generate empty data frame to hold stats from random simulations
simulations_df = data.frame(matrix(ncol=3, nrow=1000))
colnames(simulations_df) = c("mean_improvement", "prop_threshold", "ATT")
# Generate empty nested list to hold models
simul_models = list()
# Simulate random selection of features 10k+ times
r <- nrow(simulations_df)
for (sim in 1:r) {
# randomly select a quantity of pre-treatment covariates
num_vars = sample(1:pre_covars_quant, 1)
# randomly select covariates, save as "features", save in df, and in formula syntax form
features = sample(x = pre_covars, size = num_vars)
features_form = paste("college ~ ",paste(features,collapse=" + "))
# run propensity score matching model, using nearest neighbor method, linear model, ATT estimand
random_ps_att <- matchit(formula = formula(features_form),
data = ypsps_dropna_droplater, # fullest data while omitting NAs and irrelevant columns
method = "nearest",
distance = "glm",
link = "logit",
estimand = "ATT",
replace = TRUE,
ratio = 2)
# save model in df
simul_models[[sim]] <- random_ps_att
# generate summary information for the matching model, extract percent improvement, and save in df
random_ps_att_sum = summary(random_ps_att)
random_ps_att_sum_impr = random_ps_att_sum[["reduction"]]
mean_improved = mean(random_ps_att_sum_impr[,1])
simulations_df$mean_improvement[sim] <- mean_improved
# create cobalt object to fetch the proportion of covariates meeting the balance threshold, and save this proportion to the df
co_bal <- bal.tab(x = random_ps_att, thresholds = .1)
prop_bal = co_bal[["Balanced.mean.diffs"]][["count"]][1] / (co_bal[["Balanced.mean.diffs"]][["count"]][1] + co_bal[["Balanced.mean.diffs"]][["count"]][2])
simulations_df$prop_threshold[sim] = prop_bal
# save the data from the matching model and use for linear, matched regression on the political participation outcome. From this, get the ATT and save it in the df.
random_ps_att_data = match.data(random_ps_att)
features_form2 = paste("student_ppnscal ~ college + ",paste(features,collapse=" + "))
lm_ps_att = lm(formula = features_form2,
data = random_ps_att_data,
weights = weights)
lm_ps_att_sum = summary(lm_ps_att)
ATT_ps = lm_ps_att_sum$coefficients["college", "Estimate"]
simulations_df$ATT[sim] <- ATT_ps
}
